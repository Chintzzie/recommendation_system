{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Analysis (LFA) using SGD\n",
    "1.  Load data\n",
    "-  Prepocessing  \n",
    "    -  Drop 0\n",
    "    -  Convert to Sparse\n",
    "-  Define error function\n",
    "-  Using SGD to minmize error function\n",
    "-  Prediction for user already in database\n",
    "-  References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from numpy.linalg import norm \n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingData(dataFile,nrows=None):\n",
    "    \n",
    "#     if nrows =-1\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(dataFile,\n",
    "                     sep=\";\",\n",
    "                     header=0,\n",
    "                     names=[\"user\",\"isbn\",\"rating\"],\n",
    "                     encoding='iso-8859-1',\n",
    "                     nrows=nrows\n",
    "                    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work on whole data set coz its too large\n",
    "# R = df.pivot(index='user',columns='isbn',values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covertToSparse(df):\n",
    "    # sparse matrix works more efficiently\n",
    "    df['rating'] = df['rating'].astype(float)\n",
    "    df['user'] = df['user'].astype(\"category\")\n",
    "    df['isbn'] = df['isbn'].astype(\"category\")\n",
    "\n",
    "    # convert str to catergory codes because spare matrix cannot contain string\n",
    "    isbn_code = df['isbn'].cat.codes.copy()\n",
    "    user_code = df['user'].cat.codes.copy()\n",
    "\n",
    "    R = coo_matrix((df['rating'],(user_code, isbn_code)))\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBooks(df, book_threshold = 0, user_threshold = 0):\n",
    "    \n",
    "    books_ratings_count = df.isbn.value_counts() # count number of review of each book\n",
    "    users_ratings_count = df.user.value_counts() # count number of review of each book\n",
    "\n",
    "    # filtering ,obtain index\n",
    "    books_tokeep = books_ratings_count[books_ratings_count >= book_threshold]\n",
    "    users_tokeep = users_ratings_count[users_ratings_count >= user_threshold]\n",
    "    \n",
    "    # filtering\n",
    "    df_clean = df[df.isbn.isin(books_tokeep.index)]\n",
    "    df_clean = df_clean[df_clean.user.isin(users_tokeep.index)]\n",
    "    \n",
    "    \n",
    "\n",
    "    def cal_size(df):\n",
    "        r,c = df.shape\n",
    "        size = r*c\n",
    "        return size\n",
    "    \n",
    "    pc = cal_size(df_clean)/cal_size(df) * 100\n",
    "    \n",
    "    print(f\"Book, User Threshold: {(book_threshold, user_threshold )}\")\n",
    "    print(f\"INPUT SIZE: {df.shape}\")\n",
    "    print(f\"OUTPUT SIZE: {df_clean.shape}\")\n",
    "    \n",
    "    print(f\"Data size reduced to: {pc:.2f}%\")\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![error function](\\nb_img\\error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_error(R,P,Q,lambda_=0.02):\n",
    "    # error function to be minimized\n",
    "    ratings = R.data\n",
    "    rows = R.row\n",
    "    cols = R.col\n",
    "    error = 0\n",
    "    \n",
    "    for ui in range(len(ratings)):\n",
    "        rui = ratings[ui]\n",
    "        u= rows[ui]\n",
    "        i= cols[ui]\n",
    "        \n",
    "        # adding bias\n",
    "        mean = np.mean(R.data) # mean score of all rating\n",
    "        ui = np.mean(P[u,:]) # mean rating given by that user\n",
    "        bi = np.mean(Q[:,i]) # mean rating give to that movie\n",
    "        bui = mean + ui + bi\n",
    "        \n",
    "        if rui > 0:\n",
    "            rui_hat = P[u,:]@Q[:,i] + mean + ui + bi # adding bias\n",
    "            terms = [ui,bi,norm(P[u,:],2),norm(Q[:,i],2)]\n",
    "            error = error + (rui - rui_hat)**2 + \\\n",
    "                    lambda_ * sum([i**2 for i in terms])\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Function\n",
    "![sgd](\\nb_img\\sgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_bias(R,K=5,lambda_=0.02,steps=10,gamma=0.001,rmse_target=1,\n",
    "             initialize=True,P_hat=None,Q_hat=None,\n",
    "             verbose=False):\n",
    "\n",
    "    # lambda_: regularization\n",
    "    # gamma :learning rate\n",
    "    \n",
    "    if P_hat ==None and Q_hat==None:\n",
    "        # initialise matrix P and Q\n",
    "        M,N = R.shape\n",
    "        P = np.random.rand(M,K)\n",
    "        Q = np.random.rand(K,N)\n",
    "        \n",
    "    # load pretrained weights, used for predicting new user\n",
    "    elif P_hat !=None and Q_hat!=None:\n",
    "        P = P_hat\n",
    "        Q = Q_hat\n",
    "\n",
    "    #initial RMSE\n",
    "    rmse = np.sqrt(cal_error(R,P,Q,lambda_)/len(R.data))\n",
    "    print(f\"STARTING RMSE: {rmse:.2f}\")\n",
    "\n",
    "    for step in range(steps):\n",
    "        \n",
    "        for ui in range(len(R.data)):\n",
    "            rui = R.data[ui] # serialize matrix\n",
    "            u = R.row[ui] # get user index (row)\n",
    "            i = R.col[ui] # get item index (col)\n",
    "\n",
    "            # adding bias\n",
    "            mean = np.mean(R.data) # mean score of all rating\n",
    "            ui = np.mean(P[u,:]) # mean rating given by that user\n",
    "            bi = np.mean(Q[:,i]) # mean rating give to that movie\n",
    "            bui = mean + ui + bi\n",
    "    \n",
    "            # update P,Q matrix\n",
    "            rui_hat = P[u,:]@Q[:,i] + mean + ui + bi\n",
    "            eui = rui - rui_hat\n",
    "            P[u,:] = P[u,:] + gamma * (eui * Q[:,i] - lambda_ * P[u,:])  \n",
    "            Q[:,i] = Q[:,i] + gamma * (eui * P[u,:] - lambda_ * Q[:,i])  \n",
    "\n",
    "            \n",
    "        rmse = np.sqrt(cal_error(R,P,Q,lambda_)/len(R.data))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"STEP NO: {step+1} - CURRENT RMSE: {rmse:.2f}\")\n",
    "            \n",
    "        if rmse < rmse_target:\n",
    "            break\n",
    "            \n",
    "\n",
    "    print(f\"STEP NO: {step+1} - FINAL RMSE: {rmse:.2f}\")\n",
    "\n",
    "    return P,Q,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "\n",
    "nrows = None\n",
    "# nrows= 5000\n",
    "dataFile='data\\BX-Book-Ratings.csv'\n",
    "df = loadingData(dataFile,nrows)\n",
    "\n",
    "#filtering\n",
    "book_threshold,user_theshold = 10,10\n",
    "df = filterBooks(df,book_threshold,user_theshold)\n",
    "\n",
    "# block for dropping 0 values\n",
    "print(f\"DF size: {df.shape}\")\n",
    "df = df[df.rating!=0]\n",
    "print(f\"DF size after dropping 0: {df.shape}\")\n",
    "\n",
    "# convert df to sparse matrix\n",
    "R = covertToSparse(df)\n",
    "print(f\"Rating matrix shape: {R.shape}\")\n",
    "\n",
    "# sanity check\n",
    "print(f\"Number of unique users in df: {len(df.user.unique())}\")\n",
    "print(f\"Number of unique books in df: {len(df.isbn.unique())}\")\n",
    "print(f\"Number of rows and cols,i.e. unique users,books in R matrix: {R.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD\n",
    "params = {'R':R,\n",
    "          'K':5,\n",
    "          'lambda_':0.02,\n",
    "          'steps':500,\n",
    "          'gamma':0.01,\n",
    "          'verbose':True,\n",
    "          'rmse_target':1          \n",
    "         }\n",
    "\n",
    "\n",
    "\n",
    "P,Q,rmse = SGD_bias(**params)\n",
    "\n",
    "duration = time.time() - starttime\n",
    "print(f\"Process time: {duration:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# how to input new user?\n",
    "\n",
    "layer 1: user demographic, bio\n",
    "user content based filtering to generate\n",
    "\n",
    "layer 2: punch in social media account, obtain social graph \n",
    "recommend using colaborative filtering\n",
    "\n",
    "layer 3: rate some movies to cold start the LFA process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old user, look up updated R matrix\n",
    "new user, give random 10 movies to rate, , upate P matrix, reclculate PQ matrix by SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = [94100, 173415, 116122, 55490, 108950, 148898, 133706, 36299, 262070, 106849]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(np.mat('1 2; 3 4'), subok=True)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.indices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction block\n",
    "R_hat = P@Q\n",
    "\n",
    "R_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(R_hat[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(R_hat[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(R_hat,annot=False,cmap='plasma',vmax=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if oldd user read 10 books, how to prevent system from reocmmending the same 10 books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save and load trained weiights, PQ\n",
    "save and display rating matrix\n",
    "load rating matrix to predicut user behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Yehuda Koren, Robert Bell and Chris Volinsky (2019). Matrix Factorization Techniques for Recommender Systems - IEEE Journals & Magazine. [online] Ieeexplore.ieee.org. Available at: https://ieeexplore.ieee.org/document/5197422 [Accessed 10 Jan. 2019];\n",
    "https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf[Accessed 10 Jan. 2019]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SS Misc code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.conc([0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = np.array([0,0,0,0,0])\n",
    "P_prime = np.append((P,new_user),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P,Q,rmse = SGD_bias(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user = np.array([[0,7,10,0,0]])\n",
    "P_prime = np.concatenate((P,new_user))\n",
    "P_prime.shape\n",
    "\n",
    "P2,Q2, rmse = SGD_bias(**params,P_hat=P_prime,Q_hat=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1,1,1]])\n",
    "np.append(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query spare matrix\n",
    "\n",
    "df[df.user == 276726]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_hat[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrix works more efficiently\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "df['user'] = df['user'].astype(\"category\")\n",
    "df['isbn'] = df['isbn'].astype(\"category\")\n",
    "\n",
    "# convert str to catergory codes because spare matrix cannot contain string\n",
    "isbn_code = df['isbn'].cat.codes.copy()\n",
    "user_code = df['user'].cat.codes.copy()\n",
    "\n",
    "R = coo_matrix((df['rating'],(user_code, isbn_code)))\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[df.rating!=0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile='data\\BX-Book-Ratings.csv'\n",
    "\n",
    "df = pd.read_csv(dataFile,sep=\";\",\n",
    "                 header=0,\n",
    "                 names=[\"user\",\"isbn\",\"rating\"],\n",
    "                 encoding='iso-8859-1',\n",
    "                 nrows=1000\n",
    "                )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = np.array([[3,0,2],[4,1,9],[9,2,1]])\n",
    "M,N = R.shape\n",
    "K=10\n",
    "P = np.random.rand(M,K)\n",
    "Q = np.random.rand(K,N)\n",
    "cal_error(R,P,Q,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.startfile(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WRONG,NO REGULARIZATION TERMS\n",
    "\n",
    "# def SGD(R,K=5,lambda_=0.02,steps=10,gamma=0.001,verbose=False,rmse_target=1):\n",
    "\n",
    "#     # lambda_: regularization\n",
    "#     # gamma :learning rate\n",
    "    \n",
    "#     # initialise matrix P and Q\n",
    "#     M,N = R.shape\n",
    "#     P = np.random.rand(M,K)\n",
    "#     Q = np.random.rand(K,N)\n",
    "    \n",
    "#     #initial RMSE\n",
    "#     rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "#     print(f\"STARTING RMSE: {rmse:.2f}\")\n",
    "\n",
    "#     for step in range(steps):\n",
    "        \n",
    "#         for ui in range(len(R.data)):\n",
    "#             rui = R.data[ui] # serialize matrix\n",
    "#             u = R.row[ui] # get user index (row)\n",
    "#             i = R.col[ui] # get item index (col)\n",
    "\n",
    "# #             # adding bias\n",
    "# #             mean = np.mean(R.data) # mean score of all rating\n",
    "# #             ui = np.mean(P[u,:]) # mean rating given by that user\n",
    "# #             bi = np.mean(Q[:,i]) # mean rating give to that movie\n",
    "\n",
    "# #             bui = mean + ui + bi\n",
    "            \n",
    "# #             rui_hat = P[u,:] @ Q[:,i] + mean + ui + bi\n",
    "#             rui_hat = P[u,:] @ Q[:,i] # sum(row x col)\n",
    "#             error = rui - rui_hat\n",
    "\n",
    "#             # update P,Q matrix\n",
    "#             P[u,:] = P[u,:] + gamma * (error * Q[:,i] - lambda_ * P[u,:])  \n",
    "#             Q[:,i] = Q[:,i] + gamma * (error * P[u,:] - lambda_ * Q[:,i])  \n",
    "\n",
    "            \n",
    "#         rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "\n",
    "#         if verbose:\n",
    "#             print(f\"STEP NO: {step+1} - CURRENT RMSE:{rmse:.2f}\")\n",
    "            \n",
    "#         if rmse < rmse_target:\n",
    "#             break\n",
    "            \n",
    "#     if verbose:\n",
    "#         print(f\"STEP NO: {step+1} - CURRENT RMSE:{rmse:.2f}\")\n",
    "\n",
    "#     return P,Q,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE ERROR FUNCTION IS WRONG\n",
    "# # bias are not accounted for in SGD\n",
    "\n",
    "# def SGD_bias_old(R,K=5,lambda_=0.02,steps=10,gamma=0.001,verbose=False,rmse_target=1):\n",
    "\n",
    "#     # lambda_: regularization\n",
    "#     # gamma :learning rate\n",
    "    \n",
    "#     # initialise matrix P and Q\n",
    "#     M,N = R.shape\n",
    "#     P = np.random.rand(M,K)\n",
    "#     Q = np.random.rand(K,N)\n",
    "    \n",
    "#     #initial RMSE\n",
    "#     rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "#     print(f\"STARTING RMSE: {rmse:.2f}\")\n",
    "\n",
    "#     for step in range(steps):\n",
    "        \n",
    "#         for ui in range(len(R.data)):\n",
    "#             rui = R.data[ui] # serialize matrix\n",
    "#             u = R.row[ui] # get user index (row)\n",
    "#             i = R.col[ui] # get item index (col)\n",
    "\n",
    "#             # adding bias\n",
    "#             mean = np.mean(R.data) # mean score of all rating\n",
    "#             ui = np.mean(P[u,:]) # mean rating given by that user\n",
    "#             bi = np.mean(Q[:,i]) # mean rating give to that movie\n",
    "\n",
    "#             bui = mean + ui + bi\n",
    "            \n",
    "#             rui_hat = P[u,:] @ Q[:,i] + mean + ui + bi\n",
    "#             error = rui - rui_hat\n",
    "\n",
    "#             # update P,Q matrix\n",
    "#             P[u,:] = P[u,:] + gamma * (error * Q[:,i] - lambda_ * P[u,:])  \n",
    "#             Q[:,i] = Q[:,i] + gamma * (error * P[u,:] - lambda_ * Q[:,i])  \n",
    "\n",
    "            \n",
    "#         rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "\n",
    "#         if verbose:\n",
    "#             print(f\"STEP NO: {step+1} - CURRENT RMSE:{rmse:.2f}\")\n",
    "            \n",
    "#         if rmse < rmse_target:\n",
    "#             break\n",
    "            \n",
    "#     if verbose:\n",
    "#         print(f\"STEP NO: {step+1} - CURRENT RMSE:{rmse:.2f}\")\n",
    "\n",
    "#     return P,Q,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # element by element approach\n",
    "\n",
    "# def SGD_old(R,K=5,lambda_=0.02,steps=10,gamma=0.001,verbose=False,rmse_target=1):\n",
    "# # def SGD(R,K,lambda_,steps,gamma,verbose,rmse_target):    \n",
    "#     # lambda_: regularization\n",
    "#     # gamma :learning rate\n",
    "\n",
    "#     # initialise matrix P and Q\n",
    "#     M,N = R.shape\n",
    "#     P = np.random.rand(M,K)\n",
    "#     Q = np.random.rand(K,N)\n",
    "    \n",
    "#     #initial RMSE\n",
    "#     rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "#     print(f\"STARTING RMSE: {rmse:.2f}\")\n",
    "\n",
    "#     for step in range(steps):\n",
    "#         for ui in range(len(R.data)):\n",
    "#             rui = R.data[ui] # serialize matrix\n",
    "#             u = R.row[ui] # get user index (row)\n",
    "#             i = R.col[ui] # get item index (col)\n",
    "\n",
    "#             rui_hat = P[u,:] @ Q[:,i] # sum(row x col)\n",
    "#             error = rui - rui_hat\n",
    "\n",
    "#             # update P,Q matrix\n",
    "#             P[u,:] = P[u,:] + gamma * (error * Q[:,i] - lambda_ * P[u,:])  \n",
    "#             Q[:,i] = Q[:,i] + gamma * (error * P[u,:] - lambda_ * Q[:,i])  \n",
    "\n",
    "            \n",
    "#         rmse = np.sqrt(mean_squared_error(R.toarray(), P@Q))\n",
    "#         if rmse < rmse_target:\n",
    "#             break\n",
    "\n",
    "#     if verbose == True:\n",
    "#         print(f\"FINAL RMSE: {rmse:.2f}\")\n",
    "\n",
    "#     return P,Q,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection , EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.rating,\n",
    "             bins=range(10),\n",
    "             hist_kws={\"histtype\": \"step\",\n",
    "                       \"linewidth\": 3,\n",
    "                       \"alpha\": 1,\n",
    "                       \"color\": \"r\"},\n",
    "             kde=False,\n",
    "\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[df.rating!=0].rating,\n",
    "             bins=range(10),\n",
    "             hist_kws={\"histtype\": \"step\",\n",
    "                       \"linewidth\": 3,\n",
    "                       \"alpha\": 1,\n",
    "                       \"color\": \"r\"},\n",
    "             kde=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df==0,cmap='plasma_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "norm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [1,2,3]\n",
    "np.mean(a)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(42,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('user').count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = df.groupby('user').count().sort_values('rating',ascending=False).isbn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filterBooks(df, rating_threshold = 10):\n",
    "    \n",
    "#     books_ratings_count = df.isbn.value_counts() # count number of review of each book\n",
    "#     users_ratings_count = df.user.value_counts() # count number of review of each book\n",
    "\n",
    "#     # filtering ,obtain index\n",
    "#     books_tokeep = books_ratings_count[books_ratings_count >= rating_threshold]\n",
    "#     users_tokeep = users_ratings_count[users_ratings_count >= rating_threshold]\n",
    "    \n",
    "#     # filtering\n",
    "#     df_clean = df[df.isbn.isin(books_tokeep.index)]\n",
    "#     df_clean = df_clean[df_clean.user.isin(users_tokeep.index)]\n",
    "    \n",
    "#     print(f\"INPUT SIZE: {df.shape}\")\n",
    "#     print(f\"OUTPUT SIZE: {df_clean.shape}\")\n",
    "    \n",
    "#     def cal_size(df):\n",
    "#         r,c = df.shape\n",
    "#         size = r*c\n",
    "#         return size\n",
    "    \n",
    "#     pc = cal_size(df_clean)/cal_size(df) * 100\n",
    "    \n",
    "#     print(f\"Data size reduced to: {pc:.2f}%\")\n",
    "\n",
    "#     return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = filterBooks(df,2)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ratings_count = df.isbn.value_counts()\n",
    "type(books_ratings_count)\n",
    "books_ratings_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isin?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
