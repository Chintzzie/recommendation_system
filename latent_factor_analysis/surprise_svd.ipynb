{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Factor Analysis for Book Recommendation\n",
    "using the Book Crossing Datset\n",
    "\n",
    "## Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_path = '../data/BX-Book-Ratings.csv'\n",
    "raw = pd.read_csv(raw_path, \n",
    "                  sep=';',\n",
    "                  header = 0,\n",
    "                  names = ['user', 'isbn', 'rating'],\n",
    "                  encoding = 'ISO-8859-1')\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0195153448</th>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060973129</th>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0374157065</th>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0393045218</th>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "isbn                                                            \n",
       "0195153448                                Classical Mythology   \n",
       "0002005018                                       Clara Callan   \n",
       "0060973129                               Decision in Normandy   \n",
       "0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                          author  \n",
       "isbn                              \n",
       "0195153448    Mark P. O. Morford  \n",
       "0002005018  Richard Bruce Wright  \n",
       "0060973129          Carlo D'Este  \n",
       "0374157065      Gina Bari Kolata  \n",
       "0393045218       E. J. W. Barber  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookfile_path = '../data/BX-Books.csv'\n",
    "df_book = pd.read_csv( bookfile_path,\n",
    "                      sep = ';',\n",
    "                      header = 0,\n",
    "                      error_bad_lines = False,\n",
    "                      usecols = [0,1,2],\n",
    "                      index_col = 0,\n",
    "                      names = ['isbn', 'title', 'author'],\n",
    "                      encoding = 'iso-8859-1'\n",
    "                     )\n",
    "df_book.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove books without informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118605 missing books: 10.32%\n"
     ]
    }
   ],
   "source": [
    "missing_books = raw[-raw['isbn'].isin(df_book.index)]\n",
    "df_rating = raw[raw['isbn'].isin(df_book.index)]\n",
    "print( f'Found {len(missing_books)} missing books: {\"{:.2%}\".format(len(missing_books)/len(raw))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Books and Users with limited ratings\n",
    "we are setting a **threshold** here of minimum 10 ratings  \n",
    "users or books that has fewer than 10 ratings are simply not worth the effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_ratings_count = df_rating.isbn.value_counts()\n",
    "users_ratings_count = df_rating.user.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 6.47% books will be kept\n",
      "Only 12.75% users will be kept\n",
      "There are 11,746 users and 17,479 books.\n"
     ]
    }
   ],
   "source": [
    "rating_threshold = 10\n",
    "books_tokeep = books_ratings_count[books_ratings_count>= rating_threshold]\n",
    "users_tokeep = users_ratings_count[users_ratings_count>= rating_threshold]\n",
    "print(f'Only {\"{:.2%}\".format(len(books_tokeep)/ len(books_ratings_count))} books will be kept')\n",
    "print(f'Only {\"{:.2%}\".format(len(users_tokeep)/ len(users_ratings_count))} users will be kept')\n",
    "      \n",
    "print(f'There are {\"{:,}\".format(len(users_tokeep))} users and {\"{:,}\".format(len(books_tokeep))} books.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1,031,175 ratings before applying threshold, now we have 428,085\n"
     ]
    }
   ],
   "source": [
    "df_rating_clean = df_rating[ df_rating.isbn.isin(books_tokeep.index)]\n",
    "df_rating_clean = df_rating_clean[ df_rating_clean.user.isin(users_tokeep.index)]\n",
    "print( f'We have {\"{:,}\".format(len(df_rating))} ratings before applying threshold, now we have {\"{:,}\".format(len(df_rating_clean))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 284422 records that is 0: 66.44%\n"
     ]
    }
   ],
   "source": [
    "zeros = df_rating_clean[df_rating_clean.rating == 0]\n",
    "print( f'Found {len(zeros)} records that is 0: {\"{:.2%}\".format(len(zeros)/len(df_rating_clean))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143663, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating_clean = df_rating_clean[df_rating_clean.rating != 0]\n",
    "df_rating_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparseness of our rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10807 users X 17091 items and 143663 ratings. Resulting in a rating matrix that has a density of 0.08%\n"
     ]
    }
   ],
   "source": [
    "count_users = len(df_rating_clean.user.unique())\n",
    "count_items = len(df_rating_clean.isbn.unique())\n",
    "count_ratings = len(df_rating_clean)\n",
    "print(f'We have {count_users} users X {count_items} items and {count_ratings} ratings. Resulting in a rating matrix that has a density of {\"{:.2%}\".format(count_ratings/ (count_users * count_items))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Sparse Matrix\n",
    "Usage \\#3 from [documentation](https://kite.com/python/docs/scipy.sparse.coo_matrix):  \n",
    "`coo_matrix((data, (i, j)), [shape=(M, N)])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix R is of type <class 'scipy.sparse.coo.coo_matrix'> and shape (10807, 17091)\n"
     ]
    }
   ],
   "source": [
    "df_R_org = df_rating_clean.pivot( index = 'user', columns = 'isbn', values = 'rating').fillna(0)\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "# data = df_rating_clean.rating.astype(float)\n",
    "# i = df_rating_clean.user.astype('category').cat.codes.copy()\n",
    "# j = df_rating_clean.isbn.astype('category').cat.codes.copy()\n",
    "\n",
    "# R = coo_matrix(( data, (i,j)))\n",
    "R = coo_matrix( df_R_org.values)\n",
    "print(f'rating matrix R is of type {type(R)} and shape {R.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Factor Analysis with Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the observed variation in rating values is due to effects associated with either users or items, known as biases or intercepts, independent of any interactions.\n",
    "\n",
    "$b_{ui}$ = μ + $b_i$ + $b_u$\n",
    "\n",
    "For example, suppose that you want a first-order estimate for user Joe’s rating of the movie Titanic. Now, say that the average rating over all movies, μ, is 3.7 stars. Furthermore, Titanic is better than an average movie, so it tends to be rated 0.5 stars above the average.On the other hand, Joe is a critical user, who tends to rate 0.3 stars lower than the average. Thus, the estimate for Titanic’s rating by Joe would be 3.9 stars (3.7 + 0.5 - 0.3).\n",
    "\n",
    "Biases extend the Equation $r_{ui}$= $q_{i}p_{u}$ as follows:\n",
    "\n",
    "$r_{ui}$= μ+ $b_i$ + $b_u$ + $q_{i}p_{u}$\n",
    "\n",
    "The system learns by minimizing the squared error function: \n",
    "\n",
    "$min_{p,q,b}  \\sum_  rui_{k}- \\mu -b_{u}-b_{i}-p.q+ \\lambda  \\big( \\|p \\|^2+ \\|q \\|^2+\\|b_{u} \\|^2 +\\|b_{i} \\|^2\\big)  \n",
    " $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pow is power function pow(x,n) = x^n\n",
    "## e is error\n",
    "\n",
    "def error(R,P,Q,b,b_u,b_i,lamda=0.02):\n",
    "    ratings = R.data\n",
    "    rows = R.row\n",
    "    cols = R.col\n",
    "    e = 0   \n",
    "    for ui in range(len(ratings)):\n",
    "        rui=ratings[ui]\n",
    "        i = rows[ui]\n",
    "        j = cols[ui]\n",
    "        r_cap=np.dot(P[i,:],Q[:,j])+b+b_u[i]+b_i[j]\n",
    "        length_terms= [norm(P[i,:]),norm(Q[:,j]),b_u[i],b_i[j]]\n",
    "        if rui>0:\n",
    "            e= e + (rui-r_cap)**2+\\\n",
    "                lamda*(sum([i**2 for i in length_terms]))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## R coo-matrix of rating with user-books\n",
    "##  K no. of latent factors\n",
    "## lr is learning rate\n",
    "## lamda is regualarization parameter\n",
    "\n",
    "def SGD(R, K, lamda=0.02,steps=10, lr=0.001):\n",
    "    s_time = time.time()\n",
    "\n",
    "    M,N = R.shape\n",
    "    P = np.random.normal(scale=1./K,size=(M,K))\n",
    "    Q = np.random.normal(scale=1./K,size=(K,N))\n",
    "    \n",
    "    # Initialize the biases\n",
    "    # b_u the bias of users\n",
    "    # b_i the bias of books\n",
    "    b_u = np.zeros(M)\n",
    "    b_i = np.zeros(N)\n",
    "    b = np.mean(R.data)\n",
    "    \n",
    "    params = [R,P,Q,b,b_u,b_i,lamda]\n",
    "    \n",
    "    rmse = np.sqrt(error(*params)/len(R.data))\n",
    "    print(f\"Initial RMSE {'{:.4f}'.format(rmse)}\")\n",
    "    \n",
    "    for step in range(steps):\n",
    "        for ui in range(len(R.data)):\n",
    "            rui=R.data[ui]\n",
    "            u = R.row[ui]\n",
    "            i = R.col[ui]\n",
    "            if rui>0:\n",
    "                eui=rui-np.dot(P[u,:],Q[:,i])-b-b_i[i]-b_u[u]\n",
    "                # Update biases\n",
    "                b_u[u] += 2*lr * (eui - lamda * b_u[u])\n",
    "                b_i[i] += 2*lr * (eui - lamda * b_i[i])\n",
    "            \n",
    "                P[u,:]=P[u,:]+2*lr*(eui*Q[:,i]-lamda*P[u,:])  \n",
    "                Q[:,i]=Q[:,i]+2*lr*(eui*P[u,:]-lamda*Q[:,i])\n",
    "          \n",
    "        rmse = np.sqrt(error(*params)/len(R.data))\n",
    "          \n",
    "        if step%5==0:\n",
    "            print(f\"RMSE {'{:.4f}'.format(rmse)}\")\n",
    "        elif rmse <0.5:\n",
    "            break\n",
    "    \n",
    "    e_time = time.time()\n",
    "    print(f\"Final RMSE {'{:.4f}'.format(rmse)}\")\n",
    "    print(f'SGD took {\"{:.2f}\".format((e_time - s_time)/ 60)} minutes.')\n",
    "          \n",
    "    return P,Q,b_u,b_i,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE 1.7922\n",
      "RMSE 1.6935\n",
      "RMSE 1.5442\n",
      "RMSE 1.4774\n",
      "RMSE 1.4232\n",
      "RMSE 1.3739\n",
      "RMSE 1.3278\n",
      "Final RMSE 1.2892\n",
      "SGD took 2.89 minutes.\n"
     ]
    }
   ],
   "source": [
    "(P,Q,b_u,b_i,b)=SGD(R,K=10,lr=0.002,lamda=0.02, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Prediction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of SGD function output:\n",
      "P: (10807, 10)\n",
      "Q: (10, 17091)\n",
      "b_u: (10807,)\n",
      "b_i: (17091,)\n",
      "b: ()\n"
     ]
    }
   ],
   "source": [
    "sgd_outputs = {\n",
    "    'P': P,\n",
    "    'Q': Q,\n",
    "    'b_u': b_u,\n",
    "    'b_i': b_i,\n",
    "    'b': b\n",
    "              }\n",
    "print(f'Shapes of SGD function output:')\n",
    "for var in sgd_outputs:\n",
    "    print(f'{var}: {sgd_outputs[var].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_hat is type <class 'numpy.ndarray'> and shape (10807, 17091).\n"
     ]
    }
   ],
   "source": [
    "m , _ = P.shape\n",
    "_ , n = Q.shape\n",
    "R_hat =np.dot(P, Q )+ b_u.reshape(m,1) + (b_i.T).reshape(1,n) + b\n",
    "print(f'R_hat is type {type(R_hat)} and shape {R_hat.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn R_hat from a Numpy array to a DF for easier lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_R_hat = pd.DataFrame(data = R_hat, index = df_R_org.index, columns= df_R_org.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetUserRatedBooks( user_id, return_rating = False):\n",
    "    udata = df_rating_clean[ df_rating_clean.user == user_id]\n",
    "    if return_rating:\n",
    "        return {udata.iloc[i].isbn : udata.iloc[i].rating for i in range(len(udata))}\n",
    "    else:\n",
    "        return list(udata['isbn'])\n",
    "\n",
    "def GetBookDetails( isbn, field = 'title'):\n",
    "    return str(df_book[df_book.index == isbn][field].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 276847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RatingMatrixLookup( user_id , item_id, R_predicted):\n",
    "    return R_predicted[ R_predicted.index == user_id][item_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "276847    8.207228\n",
       "Name: 3404148576, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RatingMatrixLookup( uid, '3404148576', df_R_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user\n",
       "276847    8.0\n",
       "Name: 3404148576, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RatingMatrixLookup( uid, '3404148576', df_R_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPredictions( userid, df_R_hat, top_n, verbose = False):\n",
    "    if not df_R_hat.index.isin([userid]).any():\n",
    "        print(f'User {userid} does exist in rating matrix')\n",
    "        return None\n",
    "    \n",
    "    pred_df = df_R_hat[ df_R_hat.index == userid].T.sort_values(by = userid, ascending = False)\n",
    "    \n",
    "    old_books = GetUserRatedBooks(userid, return_rating = True)\n",
    "    \n",
    "    top_books = pred_df[ ~pred_df.index.isin(old_books)][:top_n].index\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'User {userid} already read:\\n---------------------')\n",
    "        for book in old_books:\n",
    "            bname = GetBookDetails(book)\n",
    "            print(f'{str(bname)}: {old_books[book]}')\n",
    "        print(f'\\nWe recommend:\\n---------------------')\n",
    "        for book in top_books:\n",
    "            bname = GetBookDetails(book)\n",
    "            print(f'{str(bname)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 276847 already read:\n",
      "---------------------\n",
      "['Nordermoor']: 8\n",
      "['Der Kleine Hobbit']: 10\n",
      "['Auf Ehre und Gewissen. Roman.']: 10\n",
      "['Asche zu Asche.']: 7\n",
      "['Denn sie betrÃ?Â¼gt man nicht.']: 8\n",
      "['Mit dem KÃ?Â¼hlschrank durch Irland.']: 10\n",
      "['Die HirnkÃ?Â¶nigin.']: 7\n",
      "['Harry Potter und der Stein der Weisen']: 10\n",
      "['Harry Potter und die Kammer des Schreckens']: 10\n",
      "['Harry Potter und der Gefangene von Azkaban']: 10\n",
      "['Harry Potter Und Der Feuerkelch']: 10\n",
      "\n",
      "We recommend:\n",
      "---------------------\n",
      "[\"My Sister's Keeper : A Novel (Picoult, Jodi)\"]\n",
      "['Dilbert: A Book of Postcards']\n",
      "['Harry Potter and the Chamber of Secrets Postcard Book']\n",
      "['84 Charing Cross Road']\n",
      "[\"The Time Traveler's Wife\"]\n",
      "['Fox in Socks (I Can Read It All by Myself Beginner Books)']\n",
      "['Calvin and Hobbes']\n",
      "['The Two Towers (The Lord of the Rings, Part 2)']\n",
      "['Weirdos From Another Planet!']\n",
      "['The Return of the King (The Lord of the Rings, Part 3)']\n",
      "['Lonesome Dove']\n",
      "['Where the Sidewalk Ends : Poems and Drawings']\n",
      "['A Tree Grows in Brooklyn']\n",
      "[\"Scientific Progress Goes 'Boink':  A Calvin and Hobbes Collection\"]\n",
      "['Route 66 Postcards: Greetings from the Mother Road']\n",
      "['Mrs. Frisby and the Rats of Nimh']\n",
      "['Postmarked Yesteryear: 30 Rare Holiday Postcards']\n",
      "['The Authoritative Calvin and Hobbes (Calvin and Hobbes)']\n",
      "['Maus a Survivors Tale: My Father Bleeds History']\n",
      "['52 Deck Series: 52 Ways to Celebrate Friendship']\n"
     ]
    }
   ],
   "source": [
    "GetPredictions( uid, df_R_hat, 20, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
